{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidnalbandyann/ACA_homework/blob/main/nlp1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Yoxu0VvyxXy"
      },
      "source": [
        "# Large scale text analysis with deep learning\n",
        "\n",
        "Today we're gonna apply the newly learned tools for the task of predicting job salary.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/3342/media/salary%20prediction%20engine%20v2.png\" width=400px>\n",
        "\n",
        "_Special thanks to [Oleg Vasilev](https://github.com/Omrigan/) for the core assignment idea._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSFmymI1yxX1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6k0fNl9yxX2"
      },
      "source": [
        "### About the challenge\n",
        "For starters, let's download and unpack the data from [here](https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=0).\n",
        "\n",
        "You can also get it from [yadisk url](https://yadi.sk/d/vVEOWPFY3NruT7) the competition [page](https://www.kaggle.com/c/job-salary-prediction/data) (pick `Train_rev1.*`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eaElJIGyxX3",
        "outputId": "ff85e8aa-80c7-4a63-faa9-81b8f99b32be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    17    0    17    0     0     77      0 --:--:-- --:--:-- --:--:--    77\n",
            "100   342  100   342    0     0    754      0 --:--:-- --:--:-- --:--:--   754\n",
            "100  119M  100  119M    0     0  12.5M      0  0:00:09  0:00:09 --:--:-- 19.3M\n",
            "Train_rev1.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(244768, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!curl -L https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1 -o Train_rev1.csv.tar.gz\n",
        "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
        "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xyf2PeoyxX4"
      },
      "source": [
        "One problem with salary prediction is that it's oddly distributed: there are many people who are paid standard salaries and a few that get tons o money. The distribution is fat-tailed on the right side, which is inconvenient for MSE minimization.\n",
        "\n",
        "There are several techniques to combat this: using a different loss function, predicting log-target instead of raw target or even replacing targets with their percentiles among all salaries in the training set. We gonna use logarithm for now.\n",
        "\n",
        "_You can read more [in the official description](https://www.kaggle.com/c/job-salary-prediction#description)._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "-F_s8HPlyxX4",
        "outputId": "249fd788-e832-4ff9-a980-2ec2deb543e5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "\n",
        "plt.figure(figsize=[8, 4])\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(data[\"SalaryNormalized\"], bins=20);\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(data['Log1pSalary'], bins=20);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1V5ihQ-yxX5"
      },
      "source": [
        "Our task is to predict one number, __Log1pSalary__.\n",
        "\n",
        "To do so, our model can access a number of features:\n",
        "* Free text: __`Title`__ and  __`FullDescription`__\n",
        "* Categorical: __`Category`__, __`Company`__, __`LocationNormalized`__, __`ContractType`__, and __`ContractTime`__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "9ax9n0ruyxX5",
        "outputId": "b1d160ca-9190-4bfb-b01d-ad11d7067f39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Id                                             Title  \\\n",
              "187885  71685213   Mechanical Design Engineer  Aberdeen  Permanent   \n",
              "174399  71434256  Area Account Manager Required  MUST HAVE OWN CAR   \n",
              "216319  72244905                     Quality Engineer  Bournemouth   \n",
              "\n",
              "                                          FullDescription  \\\n",
              "187885  Mechanical Design Engineer  Aberdeen  Permanen...   \n",
              "174399  Company Exceptional opportunity for an account...   \n",
              "216319  QUALITY ENGINEER Salary: ****k to ****k basic ...   \n",
              "\n",
              "                          LocationRaw LocationNormalized ContractType  \\\n",
              "187885         Aberdeenshire,Aberdeen                 UK          NaN   \n",
              "174399    Harrow Middlesex South East                 UK          NaN   \n",
              "216319  Bournemouth Dorset South West        Bournemouth          NaN   \n",
              "\n",
              "       ContractTime                 Company            Category  \\\n",
              "187885    permanent            Jobsite Jobs    Engineering Jobs   \n",
              "174399    permanent  Hanover IT recruitment          Sales Jobs   \n",
              "216319    permanent     Hammond Recruitment  Other/General Jobs   \n",
              "\n",
              "                                           SalaryRaw  SalaryNormalized  \\\n",
              "187885                45000.00 - 65000.00 GBP Annual             55000   \n",
              "174399               From 30,000 to 60,000 per annum             45000   \n",
              "216319  23000 - 25000 per annum + Excellent Benefits             24000   \n",
              "\n",
              "           SourceName  Log1pSalary  \n",
              "187885  jobsite.co.uk    10.915107  \n",
              "174399  totaljobs.com    10.714440  \n",
              "216319  totaljobs.com    10.085851  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-786adbe2-3657-4b1a-b002-30a21e595da8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>FullDescription</th>\n",
              "      <th>LocationRaw</th>\n",
              "      <th>LocationNormalized</th>\n",
              "      <th>ContractType</th>\n",
              "      <th>ContractTime</th>\n",
              "      <th>Company</th>\n",
              "      <th>Category</th>\n",
              "      <th>SalaryRaw</th>\n",
              "      <th>SalaryNormalized</th>\n",
              "      <th>SourceName</th>\n",
              "      <th>Log1pSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>187885</th>\n",
              "      <td>71685213</td>\n",
              "      <td>Mechanical Design Engineer  Aberdeen  Permanent</td>\n",
              "      <td>Mechanical Design Engineer  Aberdeen  Permanen...</td>\n",
              "      <td>Aberdeenshire,Aberdeen</td>\n",
              "      <td>UK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Jobsite Jobs</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>45000.00 - 65000.00 GBP Annual</td>\n",
              "      <td>55000</td>\n",
              "      <td>jobsite.co.uk</td>\n",
              "      <td>10.915107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174399</th>\n",
              "      <td>71434256</td>\n",
              "      <td>Area Account Manager Required  MUST HAVE OWN CAR</td>\n",
              "      <td>Company Exceptional opportunity for an account...</td>\n",
              "      <td>Harrow Middlesex South East</td>\n",
              "      <td>UK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Hanover IT recruitment</td>\n",
              "      <td>Sales Jobs</td>\n",
              "      <td>From 30,000 to 60,000 per annum</td>\n",
              "      <td>45000</td>\n",
              "      <td>totaljobs.com</td>\n",
              "      <td>10.714440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216319</th>\n",
              "      <td>72244905</td>\n",
              "      <td>Quality Engineer  Bournemouth</td>\n",
              "      <td>QUALITY ENGINEER Salary: ****k to ****k basic ...</td>\n",
              "      <td>Bournemouth Dorset South West</td>\n",
              "      <td>Bournemouth</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Hammond Recruitment</td>\n",
              "      <td>Other/General Jobs</td>\n",
              "      <td>23000 - 25000 per annum + Excellent Benefits</td>\n",
              "      <td>24000</td>\n",
              "      <td>totaljobs.com</td>\n",
              "      <td>10.085851</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-786adbe2-3657-4b1a-b002-30a21e595da8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-a470fdc8-7903-4d53-b339-c8557d079c74\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a470fdc8-7903-4d53-b339-c8557d079c74')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-a470fdc8-7903-4d53-b339-c8557d079c74 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-786adbe2-3657-4b1a-b002-30a21e595da8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-786adbe2-3657-4b1a-b002-30a21e595da8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "target_column = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "\n",
        "data.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OIFfyLRyxX5"
      },
      "source": [
        "### Preprocessing text data\n",
        "\n",
        "Just like last week, applying NLP to a problem begins from tokenization: splitting raw text into sequences of tokens (words, punctuation, etc).\n",
        "\n",
        "__Your task__ is to lowercase and tokenize all texts under `Title` and `FullDescription` columns. Store the tokenized data as a __space-separated__ string of tokens for performance reasons.\n",
        "\n",
        "It's okay to use nltk tokenizers. Assertions were designed for WordPunctTokenizer, slight deviations are okay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXSSLihPyxX6",
        "outputId": "16f717fd-e18b-4ec3-a597-955349c40296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw text:\n",
            "2         Mathematical Modeller / Simulation Analyst / O...\n",
            "100002    A successful and high achieving specialist sch...\n",
            "200002    Web Designer  HTML, CSS, JavaScript, Photoshop...\n",
            "Name: FullDescription, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(\"Raw text:\")\n",
        "print(data[\"FullDescription\"][2::100000])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Title']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WLwlz6zz5is",
        "outputId": "e0932e82-0446-4c6b-949d-cafa0da474d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                               Engineering Systems Analyst\n",
              "1                                   Stress Engineer Glasgow\n",
              "2                          Modelling and simulation analyst\n",
              "3         Engineering Systems Analyst / Mathematical Mod...\n",
              "4                Pioneer, Miser Engineering Systems Analyst\n",
              "                                ...                        \n",
              "244763                                   TEACHER OF SCIENCE\n",
              "244764                  TEACHER OF BUSINESS STUDIES AND ICT\n",
              "244765                                      ENGLISH TEACHER\n",
              "244766                                      SUPPLY TEACHERS\n",
              "244767                                           Accountant\n",
              "Name: Title, Length: 244768, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tK1RICWPyxX6"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "\n",
        "# see task above\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "# Sample DataFrame with 'Title' and 'FullDescription' columns\n",
        "# Function to lowercase and tokenize the text using WordPunctTokenizer\n",
        "def tokenize_text(text):\n",
        "    if isinstance(text, str):  # Check if it's a string\n",
        "        tokenizer = WordPunctTokenizer()\n",
        "        tokens = tokenizer.tokenize(text.lower())\n",
        "        return \" \".join(tokens)\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "data['Title'] = data['Title'].apply(tokenize_text)\n",
        "data['FullDescription'] = data['FullDescription'].apply(tokenize_text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9vPKI3AyxX6"
      },
      "source": [
        "Now we can assume that our text is a space-separated list of tokens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuoPkQC8yxX7",
        "outputId": "9702c8c8-bd4b-4a03-8e75-cd411383de97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJohUj9ByxX7"
      },
      "source": [
        "Not all words are equally useful. Some of them are typos or rare words that are only present a few times.\n",
        "\n",
        "Let's count how many times is each word present in the data so that we can build a \"white list\" of known words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gpe1mhk4yxX7"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
        "# build a dictionary { token -> it's count }\n",
        "title_list = data['Title'].values.tolist()\n",
        "desc_list = data['FullDescription'].values.tolist()\n",
        "full_list = title_list + desc_list\n",
        "\n",
        "def generate_words(full_list):\n",
        "    for string in full_list:\n",
        "        for word in string.split():\n",
        "            yield word\n",
        "\n",
        "list_of_words = list(generate_words(full_list))\n",
        "token_counts = Counter(list_of_words)\n",
        "#token_counts = dict(list_of_words)\n",
        "#token_counts = np.unique(list_of_words, return_counts=True)\n",
        "\n",
        "# hint: you may or may not want to use collections.Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzAqfSxgyxX8",
        "outputId": "56bcc494-2890-4740-9055-221a150491eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique tokens : 202704\n",
            "('and', 2657388)\n",
            "('.', 2523216)\n",
            "(',', 2318606)\n",
            "('the', 2080994)\n",
            "('to', 2019884)\n",
            "...\n",
            "('stephanietraveltraderecruitmnt', 1)\n",
            "('ruabon', 1)\n",
            "('lowehays', 1)\n",
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "M_vRpVKeyxX8",
        "outputId": "2098ab66-8376-43e7-f073-5481f7daa15c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Let's see how many words are there for each count\n",
        "plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\n",
        "plt.xlabel(\"Word counts\");"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_tokens = dict(token_counts)"
      ],
      "metadata": {
        "id": "_vxi9WMoHg6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOlM2cBwyxX9"
      },
      "source": [
        "Now filter tokens a list of all tokens that occur at least 10 times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kWew6LjyxX9"
      },
      "outputs": [],
      "source": [
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = [keys for keys, values in dict_tokens.items() if values>=10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_tokens_filtered = {keys: values for keys, values in dict_tokens.items() if values>=10}"
      ],
      "metadata": {
        "id": "-cNPBHGWJ5EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhHUGYocyxX9",
        "outputId": "8a6d443d-4932-4eca-c3d9-4c9f07714e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 34158\n",
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + sorted(tokens)\n",
        "print(\"Vocabulary size:\", len(tokens))\n",
        "\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_1I2LiDKqNI",
        "outputId": "2277db7e-b515-4cf6-f080-6b0caf4a5d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34158"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBh9_vFoyxX-"
      },
      "source": [
        "Build an inverse token index: a dictionary from token(string) to it's index in `tokens` (int)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kjO42KlyxX-"
      },
      "outputs": [],
      "source": [
        "#token_to_id = {value: key for key, value in dict_tokens.items()}\n",
        "#len(token_to_id)\n",
        "token_to_id = {token: index for index, token in enumerate(tokens)}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_to_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kYhtUCNNaT6",
        "outputId": "5d850b55-6643-40c5-8e35-97bbdc01f11d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'UNK': 0,\n",
              " 'PAD': 1,\n",
              " '\"': 2,\n",
              " '$': 3,\n",
              " '$****': 4,\n",
              " '$****$****': 5,\n",
              " '$****;': 6,\n",
              " '%': 7,\n",
              " '%)': 8,\n",
              " '%),': 9,\n",
              " '%).': 10,\n",
              " '%****': 11,\n",
              " '%,': 12,\n",
              " '%.': 13,\n",
              " '%/': 14,\n",
              " '%;': 15,\n",
              " '&': 16,\n",
              " '&****': 17,\n",
              " '&/': 18,\n",
              " \"'\": 19,\n",
              " \"'&\": 20,\n",
              " \"''\": 21,\n",
              " \"')\": 22,\n",
              " \"').\": 23,\n",
              " \"'****\": 24,\n",
              " \"'****'\": 25,\n",
              " \"',\": 26,\n",
              " \"'.\": 27,\n",
              " \"';\": 28,\n",
              " \"'>\": 29,\n",
              " \"'>****\": 30,\n",
              " \"'>•\": 31,\n",
              " \"'?\": 32,\n",
              " '(': 33,\n",
              " '($****': 34,\n",
              " '(%': 35,\n",
              " '(&': 36,\n",
              " \"('\": 37,\n",
              " '((': 38,\n",
              " '()': 39,\n",
              " '().': 40,\n",
              " '(****': 41,\n",
              " '(****%)': 42,\n",
              " '(****)': 43,\n",
              " '(****)(': 44,\n",
              " '(****)****': 45,\n",
              " '(****),': 46,\n",
              " '(****).': 47,\n",
              " '(********': 48,\n",
              " '(********)': 49,\n",
              " '(****/': 50,\n",
              " '(****/****': 51,\n",
              " '(****/****)': 52,\n",
              " '(****/****),': 53,\n",
              " '(****/****/****)': 54,\n",
              " '(****:': 55,\n",
              " '(****:****': 56,\n",
              " '(****:****)': 57,\n",
              " '(****:****:****)': 58,\n",
              " '(.': 59,\n",
              " '(>': 60,\n",
              " '(>****': 61,\n",
              " '(?)': 62,\n",
              " '(‘': 63,\n",
              " '(“': 64,\n",
              " ')': 65,\n",
              " ')&': 66,\n",
              " \")'\": 67,\n",
              " ')(': 68,\n",
              " '))': 69,\n",
              " ')).': 70,\n",
              " ')****': 71,\n",
              " '),': 72,\n",
              " ').': 73,\n",
              " ').•': 74,\n",
              " ')/': 75,\n",
              " '):': 76,\n",
              " ');': 77,\n",
              " ')>': 78,\n",
              " ')?': 79,\n",
              " ')–': 80,\n",
              " ')•': 81,\n",
              " '****': 82,\n",
              " '****%': 83,\n",
              " '****%)': 84,\n",
              " '****%,': 85,\n",
              " '****%.': 86,\n",
              " '****&': 87,\n",
              " '****&****': 88,\n",
              " \"****'\": 89,\n",
              " \"****'****\": 90,\n",
              " \"****'********'****\": 91,\n",
              " \"****',\": 92,\n",
              " \"****'>\": 93,\n",
              " '****(': 94,\n",
              " '****(****': 95,\n",
              " '****(****)': 96,\n",
              " '****(****)(': 97,\n",
              " '****(****)****': 98,\n",
              " '****)': 99,\n",
              " '****)****': 100,\n",
              " '****),': 101,\n",
              " '****).': 102,\n",
              " '****):': 103,\n",
              " '*******': 104,\n",
              " '********': 105,\n",
              " '********%': 106,\n",
              " '********)': 107,\n",
              " '************': 108,\n",
              " '********,': 109,\n",
              " '********.': 110,\n",
              " '********/': 111,\n",
              " '********?': 112,\n",
              " '****,': 113,\n",
              " '****.': 114,\n",
              " '****.****': 115,\n",
              " '****/': 116,\n",
              " '****/****': 117,\n",
              " '****/****)': 118,\n",
              " '****/****).': 119,\n",
              " '****/****/': 120,\n",
              " '****/****/****': 121,\n",
              " '****/****/****)': 122,\n",
              " '****/****/****/****': 123,\n",
              " '****/****:': 124,\n",
              " '****/****;': 125,\n",
              " '****:': 126,\n",
              " '****:****': 127,\n",
              " '****:****)': 128,\n",
              " '****:****),': 129,\n",
              " '****:****,': 130,\n",
              " '****:****:': 131,\n",
              " '****:****:****': 132,\n",
              " '****:****:****)': 133,\n",
              " '****:****;': 134,\n",
              " '****;': 135,\n",
              " '****;****': 136,\n",
              " '****?': 137,\n",
              " '****???': 138,\n",
              " '****[': 139,\n",
              " '****]': 140,\n",
              " '****`': 141,\n",
              " '****`****': 142,\n",
              " '****–': 143,\n",
              " '****–****': 144,\n",
              " '****’': 145,\n",
              " '****’****': 146,\n",
              " '****”': 147,\n",
              " '****…': 148,\n",
              " '++': 149,\n",
              " '++)': 150,\n",
              " '++),': 151,\n",
              " '++).': 152,\n",
              " '++,': 153,\n",
              " '++.': 154,\n",
              " '++/': 155,\n",
              " '++;': 156,\n",
              " '++?': 157,\n",
              " ',': 158,\n",
              " ',&': 159,\n",
              " ',(': 160,\n",
              " ',)': 161,\n",
              " ',).': 162,\n",
              " ',****': 163,\n",
              " ',,': 164,\n",
              " ',.': 165,\n",
              " ',/': 166,\n",
              " ',;': 167,\n",
              " ',??': 168,\n",
              " '.': 169,\n",
              " '.&': 170,\n",
              " \".'\": 171,\n",
              " '.(': 172,\n",
              " '.)': 173,\n",
              " '.),': 174,\n",
              " '.).': 175,\n",
              " '.);': 176,\n",
              " '.****': 177,\n",
              " '.****%': 178,\n",
              " '.****)': 179,\n",
              " '.********': 180,\n",
              " '.****/': 181,\n",
              " '.,': 182,\n",
              " './': 183,\n",
              " './/': 184,\n",
              " '.:': 185,\n",
              " '.;': 186,\n",
              " '.>': 187,\n",
              " '.?': 188,\n",
              " '.??': 189,\n",
              " '.]': 190,\n",
              " '.\\u200b': 191,\n",
              " '.’': 192,\n",
              " '.”': 193,\n",
              " '.•': 194,\n",
              " '.\\uf0a7': 195,\n",
              " '.\\uf0b7': 196,\n",
              " '/': 197,\n",
              " '/(': 198,\n",
              " '/)': 199,\n",
              " '/****': 200,\n",
              " '/****)': 201,\n",
              " '/****).': 202,\n",
              " '/********/': 203,\n",
              " '/****/': 204,\n",
              " '/****/****': 205,\n",
              " '/****/****)': 206,\n",
              " '/****/****/': 207,\n",
              " '/****/****/****': 208,\n",
              " '/****:': 209,\n",
              " '/****?': 210,\n",
              " '/.': 211,\n",
              " '//': 212,\n",
              " '///////': 213,\n",
              " '/>': 214,\n",
              " '/?': 215,\n",
              " '0': 216,\n",
              " '00': 217,\n",
              " '000': 218,\n",
              " '00025': 219,\n",
              " '000company': 220,\n",
              " '000market': 221,\n",
              " '000multi': 222,\n",
              " '000my': 223,\n",
              " '000the': 224,\n",
              " '001': 225,\n",
              " '005': 226,\n",
              " '00am': 227,\n",
              " '00am2': 228,\n",
              " '00am3': 229,\n",
              " '00am4': 230,\n",
              " '00am5': 231,\n",
              " '00am6': 232,\n",
              " '00m': 233,\n",
              " '00pm': 234,\n",
              " '00pm9': 235,\n",
              " '01': 236,\n",
              " '010': 237,\n",
              " '011': 238,\n",
              " '011737015': 239,\n",
              " '01189520151': 240,\n",
              " '012': 241,\n",
              " '013': 242,\n",
              " '014': 243,\n",
              " '015': 244,\n",
              " '019': 245,\n",
              " '02': 246,\n",
              " '03': 247,\n",
              " '04': 248,\n",
              " '044': 249,\n",
              " '046': 250,\n",
              " '05': 251,\n",
              " '05years': 252,\n",
              " '06': 253,\n",
              " '07': 254,\n",
              " '07788318687': 255,\n",
              " '08': 256,\n",
              " '0800': 257,\n",
              " '09': 258,\n",
              " '0am': 259,\n",
              " '0bed': 260,\n",
              " '0k': 261,\n",
              " '0m': 262,\n",
              " '0mq': 263,\n",
              " '0pm': 264,\n",
              " '1': 265,\n",
              " '10': 266,\n",
              " '100': 267,\n",
              " '1000': 268,\n",
              " '100k': 269,\n",
              " '100m': 270,\n",
              " '100million': 271,\n",
              " '1012': 272,\n",
              " '1015': 273,\n",
              " '102': 274,\n",
              " '1020': 275,\n",
              " '106': 276,\n",
              " '106pm': 277,\n",
              " '107': 278,\n",
              " '108': 279,\n",
              " '109': 280,\n",
              " '10am': 281,\n",
              " '10am2pm': 282,\n",
              " '10am3pm': 283,\n",
              " '10am4pm': 284,\n",
              " '10am5pm': 285,\n",
              " '10am6': 286,\n",
              " '10am6pm': 287,\n",
              " '10am7pm': 288,\n",
              " '10bn': 289,\n",
              " '10g': 290,\n",
              " '10hrs': 291,\n",
              " '10k': 292,\n",
              " '10m': 293,\n",
              " '10million': 294,\n",
              " '10pm': 295,\n",
              " '10pm6am': 296,\n",
              " '10th': 297,\n",
              " '10years': 298,\n",
              " '11': 299,\n",
              " '110': 300,\n",
              " '1116': 301,\n",
              " '1118': 302,\n",
              " '112': 303,\n",
              " '113': 304,\n",
              " '115': 305,\n",
              " '11am': 306,\n",
              " '11g': 307,\n",
              " '11i': 308,\n",
              " '11pm': 309,\n",
              " '11th': 310,\n",
              " '12': 311,\n",
              " '120': 312,\n",
              " '120m': 313,\n",
              " '1215': 314,\n",
              " '1216': 315,\n",
              " '1218': 316,\n",
              " '1224': 317,\n",
              " '125': 318,\n",
              " '128pm': 319,\n",
              " '12am': 320,\n",
              " '12m': 321,\n",
              " '12month': 322,\n",
              " '12months': 323,\n",
              " '12mths': 324,\n",
              " '12pm': 325,\n",
              " '12pm2pm': 326,\n",
              " '12pm8pm': 327,\n",
              " '12th': 328,\n",
              " '13': 329,\n",
              " '130': 330,\n",
              " '130m': 331,\n",
              " '13485': 332,\n",
              " '135': 333,\n",
              " '136': 334,\n",
              " '13jan13': 335,\n",
              " '13mk': 336,\n",
              " '13th': 337,\n",
              " '14': 338,\n",
              " '140': 339,\n",
              " '14001': 340,\n",
              " '145': 341,\n",
              " '14688': 342,\n",
              " '14689': 343,\n",
              " '147': 344,\n",
              " '149': 345,\n",
              " '14feb13': 346,\n",
              " '14m': 347,\n",
              " '14th': 348,\n",
              " '15': 349,\n",
              " '150': 350,\n",
              " '1500': 351,\n",
              " '15022': 352,\n",
              " '150m': 353,\n",
              " '1520': 354,\n",
              " '154': 355,\n",
              " '156': 356,\n",
              " '15am': 357,\n",
              " '15m': 358,\n",
              " '15million': 359,\n",
              " '15pm': 360,\n",
              " '15th': 361,\n",
              " '16': 362,\n",
              " '160': 363,\n",
              " '1600': 364,\n",
              " '163': 365,\n",
              " '1630': 366,\n",
              " '165million': 367,\n",
              " '16bit': 368,\n",
              " '16m': 369,\n",
              " '16th': 370,\n",
              " '17': 371,\n",
              " '170': 372,\n",
              " '1700': 373,\n",
              " '17025': 374,\n",
              " '1730': 375,\n",
              " '175': 376,\n",
              " '176': 377,\n",
              " '17m': 378,\n",
              " '17pm': 379,\n",
              " '17th': 380,\n",
              " '17week': 381,\n",
              " '18': 382,\n",
              " '180': 383,\n",
              " '1800': 384,\n",
              " '18000': 385,\n",
              " '18001': 386,\n",
              " '1824': 387,\n",
              " '183': 388,\n",
              " '185': 389,\n",
              " '18k': 390,\n",
              " '18m': 391,\n",
              " '18months': 392,\n",
              " '18th': 393,\n",
              " '19': 394,\n",
              " '190': 395,\n",
              " '197': 396,\n",
              " '1973': 397,\n",
              " '1974': 398,\n",
              " '1976': 399,\n",
              " '1978': 400,\n",
              " '1980': 401,\n",
              " '1982': 402,\n",
              " '1983': 403,\n",
              " '1984': 404,\n",
              " '1985': 405,\n",
              " '1986': 406,\n",
              " '1987': 407,\n",
              " '1988': 408,\n",
              " '1989': 409,\n",
              " '199': 410,\n",
              " '1990': 411,\n",
              " '1991': 412,\n",
              " '1992': 413,\n",
              " '1993': 414,\n",
              " '1994': 415,\n",
              " '1995': 416,\n",
              " '1996': 417,\n",
              " '1997': 418,\n",
              " '1998': 419,\n",
              " '1999': 420,\n",
              " '19jan13': 421,\n",
              " '19th': 422,\n",
              " '1a': 423,\n",
              " '1aa': 424,\n",
              " '1am': 425,\n",
              " '1b': 426,\n",
              " '1bn': 427,\n",
              " '1k': 428,\n",
              " '1lp': 429,\n",
              " '1m': 430,\n",
              " '1million': 431,\n",
              " '1nn': 432,\n",
              " '1nx': 433,\n",
              " '1pgrjobs': 434,\n",
              " '1pm': 435,\n",
              " '1pm3': 436,\n",
              " '1st': 437,\n",
              " '1st3rd': 438,\n",
              " '1stassistantmanager_job': 439,\n",
              " '1stplacegraduaterecruitment': 440,\n",
              " '1week': 441,\n",
              " '1years': 442,\n",
              " '2': 443,\n",
              " '20': 444,\n",
              " '200': 445,\n",
              " '2000': 446,\n",
              " '20000': 447,\n",
              " '2001': 448,\n",
              " '2002': 449,\n",
              " '20022': 450,\n",
              " '2003': 451,\n",
              " '2004': 452,\n",
              " '2005': 453,\n",
              " '2006': 454,\n",
              " '2007': 455,\n",
              " '2008': 456,\n",
              " '2008r': 457,\n",
              " '2008r2': 458,\n",
              " '2009': 459,\n",
              " '200m': 460,\n",
              " '200million': 461,\n",
              " '201': 462,\n",
              " '2010': 463,\n",
              " '2011': 464,\n",
              " '2011number': 465,\n",
              " '2012': 466,\n",
              " '2013': 467,\n",
              " '2013interview': 468,\n",
              " '2013the': 469,\n",
              " '2014': 470,\n",
              " '2015': 471,\n",
              " '201513': 472,\n",
              " '2016': 473,\n",
              " '2017': 474,\n",
              " '2018': 475,\n",
              " '2019': 476,\n",
              " '202011': 477,\n",
              " '2025': 478,\n",
              " '2030': 479,\n",
              " '20a': 480,\n",
              " '20annex': 481,\n",
              " '20application': 482,\n",
              " '20convictions': 483,\n",
              " '20days': 484,\n",
              " '20feb': 485,\n",
              " '20form': 486,\n",
              " '20hrs': 487,\n",
              " '20jan13': 488,\n",
              " '20k': 489,\n",
              " '20m': 490,\n",
              " '20million': 491,\n",
              " '20pm': 492,\n",
              " '20th': 493,\n",
              " '21': 494,\n",
              " '210': 495,\n",
              " '21st': 496,\n",
              " '22': 497,\n",
              " '220': 498,\n",
              " '22000': 499,\n",
              " '22k': 500,\n",
              " '22nd': 501,\n",
              " '23': 502,\n",
              " '23000': 503,\n",
              " '230strong': 504,\n",
              " '237': 505,\n",
              " '23feb': 506,\n",
              " '23rd': 507,\n",
              " '24': 508,\n",
              " '240': 509,\n",
              " '24hour': 510,\n",
              " '24th': 511,\n",
              " '25': 512,\n",
              " '250': 513,\n",
              " '250450': 514,\n",
              " '250m': 515,\n",
              " '2530': 516,\n",
              " '25days': 517,\n",
              " '25hrs': 518,\n",
              " '25k': 519,\n",
              " '25m': 520,\n",
              " '25million': 521,\n",
              " '25th': 522,\n",
              " '26': 523,\n",
              " '260': 524,\n",
              " '26262': 525,\n",
              " '2630': 526,\n",
              " '26jan': 527,\n",
              " '26th': 528,\n",
              " '27': 529,\n",
              " '27000': 530,\n",
              " '27001': 531,\n",
              " '275': 532,\n",
              " '279': 533,\n",
              " '27jan': 534,\n",
              " '27k': 535,\n",
              " '27m': 536,\n",
              " '27th': 537,\n",
              " '28': 538,\n",
              " '280': 539,\n",
              " '28k': 540,\n",
              " '28pm': 541,\n",
              " '28th': 542,\n",
              " '29': 543,\n",
              " '29th': 544,\n",
              " '2aa': 545,\n",
              " '2am': 546,\n",
              " '2b': 547,\n",
              " '2bn': 548,\n",
              " '2d': 549,\n",
              " '2form': 550,\n",
              " '2hrs': 551,\n",
              " '2ju': 552,\n",
              " '2k': 553,\n",
              " '2m': 554,\n",
              " '2million': 555,\n",
              " '2months': 556,\n",
              " '2nd': 557,\n",
              " '2ndline': 558,\n",
              " '2pm': 559,\n",
              " '2pm10pm': 560,\n",
              " '2week': 561,\n",
              " '2x': 562,\n",
              " '2years': 563,\n",
              " '2yrs': 564,\n",
              " '3': 565,\n",
              " '30': 566,\n",
              " '300': 567,\n",
              " '300m': 568,\n",
              " '300million': 569,\n",
              " '3035': 570,\n",
              " '3035k': 571,\n",
              " '304': 572,\n",
              " '3040': 573,\n",
              " '305': 574,\n",
              " '3050': 575,\n",
              " '305pm': 576,\n",
              " '306': 577,\n",
              " '306pm': 578,\n",
              " '308': 579,\n",
              " '309pm': 580,\n",
              " '30am': 581,\n",
              " '30am1': 582,\n",
              " '30am12': 583,\n",
              " '30am1pm': 584,\n",
              " '30am3': 585,\n",
              " '30am4': 586,\n",
              " '30am4pm': 587,\n",
              " '30am5': 588,\n",
              " '30am5pm': 589,\n",
              " '30am6': 590,\n",
              " '30am6pm': 591,\n",
              " '30am8': 592,\n",
              " '30children': 593,\n",
              " '30countries': 594,\n",
              " '30hrs': 595,\n",
              " '30k': 596,\n",
              " '30m': 597,\n",
              " '30million': 598,\n",
              " '30pm': 599,\n",
              " '30pm7': 600,\n",
              " '30pm8': 601,\n",
              " '30pm9': 602,\n",
              " '30pm9pm': 603,\n",
              " '30th': 604,\n",
              " '31': 605,\n",
              " '310': 606,\n",
              " '312': 607,\n",
              " '31st': 608,\n",
              " '32': 609,\n",
              " '320': 610,\n",
              " '32bit': 611,\n",
              " '33': 612,\n",
              " '333': 613,\n",
              " '336': 614,\n",
              " '33k': 615,\n",
              " '34': 616,\n",
              " '340': 617,\n",
              " '35': 618,\n",
              " '350': 619,\n",
              " '35000': 620,\n",
              " '350m': 621,\n",
              " '35635': 622,\n",
              " '35k': 623,\n",
              " '35m': 624,\n",
              " '36': 625,\n",
              " '360': 626,\n",
              " '365': 627,\n",
              " '36months': 628,\n",
              " '37': 629,\n",
              " '371': 630,\n",
              " '37hour': 631,\n",
              " '37hrs': 632,\n",
              " '38': 633,\n",
              " '39': 634,\n",
              " '39hrs': 635,\n",
              " '3aa': 636,\n",
              " '3am': 637,\n",
              " '3bn': 638,\n",
              " '3d': 639,\n",
              " '3days': 640,\n",
              " '3e': 641,\n",
              " '3g': 642,\n",
              " '3gpp': 643,\n",
              " '3k': 644,\n",
              " '3m': 645,\n",
              " '3million': 646,\n",
              " '3month': 647,\n",
              " '3months': 648,\n",
              " '3par': 649,\n",
              " '3pl': 650,\n",
              " '3pm': 651,\n",
              " '3pm11pm': 652,\n",
              " '3rd': 653,\n",
              " '3rdparty': 654,\n",
              " '3x': 655,\n",
              " '3years': 656,\n",
              " '3yrs': 657,\n",
              " '4': 658,\n",
              " '40': 659,\n",
              " '400': 660,\n",
              " '4000': 661,\n",
              " '40000': 662,\n",
              " '400m': 663,\n",
              " '4045': 664,\n",
              " '40hrs': 665,\n",
              " '40k': 666,\n",
              " '40m': 667,\n",
              " '40million': 668,\n",
              " '41': 669,\n",
              " '410': 670,\n",
              " '415': 671,\n",
              " '42': 672,\n",
              " '43': 673,\n",
              " '44': 674,\n",
              " '45': 675,\n",
              " '450': 676,\n",
              " '4550': 677,\n",
              " '45am': 678,\n",
              " '45am6pm': 679,\n",
              " '45k': 680,\n",
              " '45m': 681,\n",
              " '45pm': 682,\n",
              " '46': 683,\n",
              " '47': 684,\n",
              " '48': 685,\n",
              " '48pm': 686,\n",
              " '49': 687,\n",
              " '4am': 688,\n",
              " '4children': 689,\n",
              " '4d': 690,\n",
              " '4days': 691,\n",
              " '4hrs': 692,\n",
              " '4k': 693,\n",
              " '4m': 694,\n",
              " '4million': 695,\n",
              " '4off': 696,\n",
              " '4on': 697,\n",
              " '4pm': 698,\n",
              " '4pm8pm': 699,\n",
              " '4social': 700,\n",
              " '4star': 701,\n",
              " '4th': 702,\n",
              " '4week': 703,\n",
              " '5': 704,\n",
              " '50': 705,\n",
              " '500': 706,\n",
              " '500m': 707,\n",
              " '5060': 708,\n",
              " '50am': 709,\n",
              " '50k': 710,\n",
              " '50m': 711,\n",
              " '50million': 712,\n",
              " '50pm': 713,\n",
              " '51': 714,\n",
              " '510': 715,\n",
              " '515': 716,\n",
              " '52': 717,\n",
              " '53': 718,\n",
              " '530pm': 719,\n",
              " '54': 720,\n",
              " '55': 721,\n",
              " '550m': 722,\n",
              " '551': 723,\n",
              " '55th': 724,\n",
              " '56': 725,\n",
              " '57': 726,\n",
              " '58': 727,\n",
              " '59': 728,\n",
              " '59pm': 729,\n",
              " '5am': 730,\n",
              " '5billion': 731,\n",
              " '5days': 732,\n",
              " '5hours': 733,\n",
              " '5hrs': 734,\n",
              " '5k': 735,\n",
              " '5m': 736,\n",
              " '5mb': 737,\n",
              " '5million': 738,\n",
              " '5pm': 739,\n",
              " '5pm9pm': 740,\n",
              " '5q': 741,\n",
              " '5s': 742,\n",
              " '5star': 743,\n",
              " '5th': 744,\n",
              " '5why': 745,\n",
              " '5x': 746,\n",
              " '5y': 747,\n",
              " '5years': 748,\n",
              " '5yrs': 749,\n",
              " '6': 750,\n",
              " '60': 751,\n",
              " '600': 752,\n",
              " '600m': 753,\n",
              " '60k': 754,\n",
              " '60m': 755,\n",
              " '61': 756,\n",
              " '610': 757,\n",
              " '610am': 758,\n",
              " '612': 759,\n",
              " '61656': 760,\n",
              " '62': 761,\n",
              " '63': 762,\n",
              " '64': 763,\n",
              " '64bit': 764,\n",
              " '65': 765,\n",
              " '65365': 766,\n",
              " '65822': 767,\n",
              " '65m': 768,\n",
              " '66': 769,\n",
              " '67': 770,\n",
              " '670': 771,\n",
              " '68': 772,\n",
              " '68am': 773,\n",
              " '69': 774,\n",
              " '69am': 775,\n",
              " '6am': 776,\n",
              " '6am2pm': 777,\n",
              " '6am6pm': 778,\n",
              " '6jb': 779,\n",
              " '6k': 780,\n",
              " '6m': 781,\n",
              " '6million': 782,\n",
              " '6month': 783,\n",
              " '6months': 784,\n",
              " '6pm': 785,\n",
              " '6pm6am': 786,\n",
              " '6th': 787,\n",
              " '6weeks': 788,\n",
              " '7': 789,\n",
              " '70': 790,\n",
              " '700': 791,\n",
              " '7000': 792,\n",
              " '70m': 793,\n",
              " '71': 794,\n",
              " '710': 795,\n",
              " '712': 796,\n",
              " '72': 797,\n",
              " '73': 798,\n",
              " '74': 799,\n",
              " '75': 800,\n",
              " '750': 801,\n",
              " '750m': 802,\n",
              " '75m': 803,\n",
              " '76': 804,\n",
              " '77': 805,\n",
              " '78': 806,\n",
              " '79': 807,\n",
              " '7am': 808,\n",
              " '7am10am': 809,\n",
              " '7am11am': 810,\n",
              " '7am11pm': 811,\n",
              " '7am2pm': 812,\n",
              " '7am3': 813,\n",
              " '7am3pm': 814,\n",
              " '7am4pm': 815,\n",
              " '7am5pm': 816,\n",
              " '7am7pm': 817,\n",
              " '7days': 818,\n",
              " '7k': 819,\n",
              " '7m': 820,\n",
              " '7million': 821,\n",
              " '7pm': 822,\n",
              " '7pm7am': 823,\n",
              " '7th': 824,\n",
              " '8': 825,\n",
              " '80': 826,\n",
              " '800': 827,\n",
              " '80800': 828,\n",
              " '8090': 829,\n",
              " '80m': 830,\n",
              " '81': 831,\n",
              " '810': 832,\n",
              " '812': 833,\n",
              " '82': 834,\n",
              " '8226': 835,\n",
              " '8232': 836,\n",
              " '83': 837,\n",
              " '84': 838,\n",
              " '85': 839,\n",
              " '850m': 840,\n",
              " '85pm': 841,\n",
              " '86': 842,\n",
              " '87': 843,\n",
              " '88': 844,\n",
              " '88pm': 845,\n",
              " '89': 846,\n",
              " '896': 847,\n",
              " '8a': 848,\n",
              " '8am': 849,\n",
              " '8am12pm': 850,\n",
              " '8am1pm': 851,\n",
              " '8am2pm': 852,\n",
              " '8am4': 853,\n",
              " '8am4pm': 854,\n",
              " '8am5': 855,\n",
              " '8am5pm': 856,\n",
              " '8am6pm': 857,\n",
              " '8am7pm': 858,\n",
              " '8am8pm': 859,\n",
              " '8am9pm': 860,\n",
              " '8c': 861,\n",
              " '8d': 862,\n",
              " '8m': 863,\n",
              " '8pm': 864,\n",
              " '8pm8am': 865,\n",
              " '8sb': 866,\n",
              " '8th': 867,\n",
              " '9': 868,\n",
              " '90': 869,\n",
              " '900': 870,\n",
              " '9000': 871,\n",
              " '9001': 872,\n",
              " '9001en': 873,\n",
              " '9002': 874,\n",
              " '90day': 875,\n",
              " '90m': 876,\n",
              " '91': 877,\n",
              " '912': 878,\n",
              " '92': 879,\n",
              " '93': 880,\n",
              " '9320100': 881,\n",
              " '94': 882,\n",
              " '95': 883,\n",
              " '95pm': 884,\n",
              " '96': 885,\n",
              " '9632': 886,\n",
              " '96pm': 887,\n",
              " '97': 888,\n",
              " '98': 889,\n",
              " '99': 890,\n",
              " '997': 891,\n",
              " '998': 892,\n",
              " '9am': 893,\n",
              " '9am12pm': 894,\n",
              " '9am1pm': 895,\n",
              " '9am2pm': 896,\n",
              " '9am3pm': 897,\n",
              " '9am4pm': 898,\n",
              " '9am5': 899,\n",
              " '9am5pm': 900,\n",
              " '9am6pm': 901,\n",
              " '9am9pm': 902,\n",
              " '9months': 903,\n",
              " '9ph': 904,\n",
              " '9pm': 905,\n",
              " '9th': 906,\n",
              " ':': 907,\n",
              " ':&': 908,\n",
              " \":'\": 909,\n",
              " ':(': 910,\n",
              " ':)': 911,\n",
              " ':****': 912,\n",
              " ':****)': 913,\n",
              " ':********': 914,\n",
              " ':****/': 915,\n",
              " ':****/****': 916,\n",
              " ':****/****/': 917,\n",
              " ':****:': 918,\n",
              " ':****:****': 919,\n",
              " ':,': 920,\n",
              " ':.': 921,\n",
              " ':/': 922,\n",
              " '://': 923,\n",
              " '::': 924,\n",
              " ':>': 925,\n",
              " ':?': 926,\n",
              " ':•': 927,\n",
              " ';': 928,\n",
              " ';)': 929,\n",
              " ';****': 930,\n",
              " ';****/': 931,\n",
              " ';****;****;': 932,\n",
              " ';,': 933,\n",
              " ';.': 934,\n",
              " ';;': 935,\n",
              " ';•': 936,\n",
              " '<': 937,\n",
              " '>': 938,\n",
              " '>****': 939,\n",
              " '>>': 940,\n",
              " '>>>': 941,\n",
              " '>??': 942,\n",
              " '?': 943,\n",
              " \"?'\": 944,\n",
              " '?)': 945,\n",
              " '?).': 946,\n",
              " '?****': 947,\n",
              " '?,': 948,\n",
              " '?.': 949,\n",
              " '?:': 950,\n",
              " '??': 951,\n",
              " '??,': 952,\n",
              " '??.': 953,\n",
              " '???': 954,\n",
              " '????': 955,\n",
              " '??????': 956,\n",
              " '??????????': 957,\n",
              " '????????????': 958,\n",
              " '??????????????': 959,\n",
              " '?”': 960,\n",
              " '[': 961,\n",
              " ']': 962,\n",
              " '],': 963,\n",
              " '],****': 964,\n",
              " '].': 965,\n",
              " ']/': 966,\n",
              " ']:': 967,\n",
              " '^': 968,\n",
              " '_': 969,\n",
              " '__': 970,\n",
              " '_____________________': 971,\n",
              " '___________________________': 972,\n",
              " '________________________________________': 973,\n",
              " '______________________________________________________________________________': 974,\n",
              " '_a': 975,\n",
              " '_experience': 976,\n",
              " '_job': 977,\n",
              " '`': 978,\n",
              " '`,': 979,\n",
              " '`.': 980,\n",
              " '``': 981,\n",
              " 'a': 982,\n",
              " 'a1': 983,\n",
              " 'a1cae': 984,\n",
              " 'a2': 985,\n",
              " 'a24': 986,\n",
              " 'a24connect': 987,\n",
              " 'a3': 988,\n",
              " 'a4': 989,\n",
              " 'a400m': 990,\n",
              " 'a4e': 991,\n",
              " 'a4lfw4l': 992,\n",
              " 'a4lg': 993,\n",
              " 'aa': 994,\n",
              " 'aaa': 995,\n",
              " 'aaad': 996,\n",
              " 'aaappointments': 997,\n",
              " 'aab': 998,\n",
              " 'aac': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIIEezJ1yxX-",
        "outputId": "740fc84e-76a6-4af0-c8bd-b90ae0eb0539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JySgILkxyxX_"
      },
      "source": [
        "And finally, let's use the vocabulary you've built to map text lines into neural network-digestible matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGl0TBtbyxX_"
      },
      "outputs": [],
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "\n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "\n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "\n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qssGzaySyxX_",
        "outputId": "8b245e40-e058-45f5-e68f-7bd534660ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[10807 30161  2166     1     1]\n",
            " [15020  2844     1     1     1]\n",
            " [27645 10201    16 15215 10804]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FZRboZKyxX_"
      },
      "source": [
        "Now let's  encode the categirical data we have.\n",
        "\n",
        "As usual, we shall use one-hot encoding for simplicity. Kudos if you use more advanced encodings: tf-idf, pretrained w2v etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "-VK0NnBeyxYA",
        "outputId": "2f10e9d3-c163-42de-b14b-8dfd91dd4c88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPRNQSTxyxYA"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj0mWoM6yxYA",
        "outputId": "d3167f45-bd56-48ad-baa2-7bbc4ff1110e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size =  195814\n",
            "Validation size =  48954\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3mNkdcuyxYA"
      },
      "outputs": [],
      "source": [
        "def make_batch(data, max_len=None, word_dropout=0):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "\n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "\n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "\n",
        "    return batch\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im6nQbQ2yxYB",
        "outputId": "6ee6cd94-0775-433a-f777-cfa7318cffab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Title': array([[27645, 29893, 33674,     1,     1,     1,     1],\n",
              "        [29239,   197, 19175, 20042, 15554, 23162,  4051],\n",
              "        [10609, 30412, 17746,    33,  8705, 29157,    65]], dtype=int32),\n",
              " 'FullDescription': array([[27645, 29893, 33674, 32939,   982, 27645, 29893, 33674, 16451,\n",
              "         32939],\n",
              "        [29239,   197, 19175, 20042, 15554, 23162,  4051, 25511,   907,\n",
              "            82],\n",
              "        [30746, 21956, 20601,  6409, 16451,  8165, 27493,   982, 30412,\n",
              "         17746]], dtype=int32),\n",
              " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " 'Log1pSalary': array([ 9.71154 , 10.463132, 10.71444 ], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "make_batch(data_train[:3], max_len=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmM5ITMfyxYB"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our basic model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo_EGJslyxYB"
      },
      "source": [
        "This clearly doesn't fit into keras' __Sequential__ interface. To build such a network, one will have to use __[Keras Functional API](https://keras.io/models/model/)__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCndDQNbyxYB"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import keras.layers as L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR6eyqWsyxYB"
      },
      "outputs": [],
      "source": [
        "def build_model(n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=64):\n",
        "    \"\"\" Build a model that maps three data sources to a single linear output: predicted log1p(salary) \"\"\"\n",
        "\n",
        "    # Input layers for Title, FullDescription, and Categorical features\n",
        "    l_title = L.Input(shape=[None], name=\"Title\")\n",
        "    l_descr = L.Input(shape=[None], name=\"FullDescription\")\n",
        "    l_categ = L.Input(shape=[n_cat_features], name=\"Categorical\")\n",
        "\n",
        "    emb_title = L.Embedding(input_dim=n_tokens, output_dim=hid_size)(l_title)\n",
        "    title_lstm = L.LSTM(hid_size)(emb_title)\n",
        "    emb_descr = L.Embedding(input_dim=n_tokens, output_dim=hid_size)(l_descr)\n",
        "    descr_lstm = L.LSTM(hid_size)(emb_descr)\n",
        "    categ_dense = L.Dense(hid_size)(l_categ)\n",
        "    concat_layer = L.Concatenate()([title_lstm, descr_lstm, categ_dense])\n",
        "    output_layer = L.Dense(1)(concat_layer)\n",
        "\n",
        "    model = keras.models.Model(inputs=[l_title, l_descr, l_categ], outputs=[output_layer])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxFZiXniyxYB",
        "outputId": "0c0eb1e6-79d2-4c87-9d4d-730ee9aab851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Title (InputLayer)             [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " FullDescription (InputLayer)   [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 64)     2186112     ['Title[0][0]']                  \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 64)     2186112     ['FullDescription[0][0]']        \n",
            "                                                                                                  \n",
            " Categorical (InputLayer)       [(None, 3768)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 64)           33024       ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 64)           33024       ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           241216      ['Categorical[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 192)          0           ['lstm[0][0]',                   \n",
            "                                                                  'lstm_1[0][0]',                 \n",
            "                                                                  'dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            193         ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,679,681\n",
            "Trainable params: 4,679,681\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py:639: UserWarning: Input dict contained keys ['Log1pSalary'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 87ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py:639: UserWarning: Input dict contained keys ['Log1pSalary'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n"
          ]
        }
      ],
      "source": [
        "model = build_model()\n",
        "model.summary()\n",
        "\n",
        "dummy_pred = model.predict(make_batch(data_train[:100]))\n",
        "dummy_loss = model.train_on_batch(make_batch(data_train[:100]), data_train['Log1pSalary'][:100])[0]\n",
        "assert dummy_pred.shape == (100, 1)\n",
        "assert len(np.unique(dummy_pred)) > 20, \"model returns suspiciously few unique outputs. Check your initialization\"\n",
        "assert np.ndim(dummy_loss) == 0 and 0. <= dummy_loss <= 250., \"make sure you minimize MSE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGhKs8IHyxYB"
      },
      "source": [
        "#### Training and evaluation\n",
        "\n",
        "As usual, we gonna feed our model with random minibatches of data.\n",
        "\n",
        "As we train, we want to monitor not only loss function, which is computed in log-space, but also the actual error measured in dollars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP6jurrNyxYC"
      },
      "outputs": [],
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            target = batch.pop(target_column)\n",
        "            yield batch, target\n",
        "\n",
        "        if not cycle: break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cDjenRvSSTPO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMpZPlZnyxYC"
      },
      "source": [
        "### Model training\n",
        "\n",
        "We can now fit our model the usual minibatch way. The interesting part is that we train on an infinite stream of minibatches, produced by `iterate_minibatches` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "9rpK8LTOyxYC",
        "outputId": "7704d389-767c-466b-9106-e528d1677add"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-2cd289f91ed9>:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(iterate_minibatches(data_train, batch_size, cycle=True, word_dropout=0.05),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 488s 5s/step - loss: 16.6419 - mean_absolute_error: 2.3173 - val_loss: 0.2219 - val_mean_absolute_error: 0.3780\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2071 - mean_absolute_error: 0.3631"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-2cd289f91ed9>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m model.fit_generator(iterate_minibatches(data_train, batch_size, cycle=True, word_dropout=0.05), \n\u001b[0m\u001b[1;32m      8\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m         )\n\u001b[0;32m-> 2636\u001b[0;31m         return self.fit(\n\u001b[0m\u001b[1;32m   2637\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1727\u001b[0m                             \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         )\n\u001b[0;32m-> 1729\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1730\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2070\u001b[0m                         ):\n\u001b[1;32m   2071\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "epochs = 10            # definitely too small\n",
        "steps_per_epoch = 100  # for full pass over data: (len(data_train) - 1) // batch_size + 1\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "model.fit_generator(iterate_minibatches(data_train, batch_size, cycle=True, word_dropout=0.05),\n",
        "                    epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
        "\n",
        "                    validation_data=iterate_minibatches(data_val, batch_size, cycle=True),\n",
        "                    validation_steps=data_val.shape[0] // batch_size\n",
        "                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_bCXadgyxYC"
      },
      "outputs": [],
      "source": [
        "def print_metrics(model, data, batch_size=batch_size, name=\"\", **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    for batch_x, batch_y in iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw):\n",
        "        batch_pred = model.predict(batch_x)[:, 0]\n",
        "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
        "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
        "        num_samples += len(batch_y)\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
        "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
        "    return squared_error, abs_error\n",
        "\n",
        "print_metrics(model, data_train, name='Train')\n",
        "print_metrics(model, data_val, name='Val');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3-ued5PyxYD"
      },
      "source": [
        "### Bonus part: explaining model predictions\n",
        "\n",
        "It's usually a good idea to understand how your model works before you let it make actual decisions. It's simple for linear models: just see which words learned positive or negative weights. However, its much harder for neural networks that learn complex nonlinear dependencies.\n",
        "\n",
        "There are, however, some ways to look inside the black box:\n",
        "* Seeing how model responds to input perturbations\n",
        "* Finding inputs that maximize/minimize activation of some chosen neurons (_read more [on distill.pub](https://distill.pub/2018/building-blocks/)_)\n",
        "* Building local linear approximations to your neural network: [article](https://arxiv.org/abs/1602.04938), [eli5 library](https://github.com/TeamHG-Memex/eli5/tree/master/eli5/formatters)\n",
        "\n",
        "Today we gonna try the first method just because it's the simplest one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAHVVk8cyxYD"
      },
      "outputs": [],
      "source": [
        "def explain(model, sample, col_name='Title'):\n",
        "    \"\"\" Computes the effect each word had on model predictions \"\"\"\n",
        "    sample = dict(sample)\n",
        "    sample_col_tokens = [tokens[token_to_id.get(tok, 0)] for tok in sample[col_name].split()]\n",
        "    data_drop_one_token = pd.DataFrame([sample] * (len(sample_col_tokens) + 1))\n",
        "\n",
        "    for drop_i in range(len(sample_col_tokens)):\n",
        "        data_drop_one_token.loc[drop_i, col_name] = ' '.join(UNK if i == drop_i else tok\n",
        "                                                   for i, tok in enumerate(sample_col_tokens))\n",
        "\n",
        "    *predictions_drop_one_token, baseline_pred = model.predict(make_batch(data_drop_one_token))[:, 0]\n",
        "    diffs = baseline_pred - predictions_drop_one_token\n",
        "    return list(zip(sample_col_tokens, diffs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acj0lVrmyxYD"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display_html\n",
        "\n",
        "def draw_html(tokens_and_weights, cmap=plt.get_cmap(\"bwr\"), display=True,\n",
        "              token_template=\"\"\"<span style=\"background-color: {color_hex}\">{token}</span>\"\"\",\n",
        "              font_style=\"font-size:14px;\"\n",
        "             ):\n",
        "\n",
        "    def get_color_hex(weight):\n",
        "        rgba = cmap(1. / (1 + np.exp(weight)), bytes=True)\n",
        "        return '#%02X%02X%02X' % rgba[:3]\n",
        "\n",
        "    tokens_html = [\n",
        "        token_template.format(token=token, color_hex=get_color_hex(weight))\n",
        "        for token, weight in tokens_and_weights\n",
        "    ]\n",
        "\n",
        "\n",
        "    raw_html = \"\"\"<p style=\"{}\">{}</p>\"\"\".format(font_style, ' '.join(tokens_html))\n",
        "    if display:\n",
        "        display_html(HTML(raw_html))\n",
        "\n",
        "    return raw_html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ocfzBztyxYD"
      },
      "outputs": [],
      "source": [
        "i = 36605\n",
        "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
        "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
        "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ph4GFlntyxYD"
      },
      "outputs": [],
      "source": [
        "i = 12077\n",
        "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
        "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
        "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q50jJ6iNyxYD"
      },
      "outputs": [],
      "source": [
        "i = np.random.randint(len(data))\n",
        "print(\"Index:\", i)\n",
        "print(\"Salary (gbp):\", np.expm1(model.predict(make_batch(data.iloc[i: i+1]))[0, 0]))\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
        "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
        "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w4uX86ayxYE"
      },
      "source": [
        "__Terrible start-up idea #1962:__ make a tool that automaticaly rephrases your job description (or CV) to meet salary expectations :)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}